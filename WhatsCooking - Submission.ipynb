{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.json', encoding='utf-8') as f:\n",
    "    train = json.load(f)\n",
    "with open('test.json', encoding='utf-8') as f:\n",
    "    test = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train)\n",
    "test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id      cuisine                                        ingredients\n",
      "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
      "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
      "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
      "3  22213       indian                [water, vegetable oil, wheat, salt]\n",
      "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...\n",
      "(39774, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.head())\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                        ingredients\n",
      "0  18009  [baking powder, eggs, all-purpose flour, raisi...\n",
      "1  28583  [sugar, egg yolks, corn starch, cream of tarta...\n",
      "2  41580  [sausage links, fennel bulb, fronds, olive oil...\n",
      "3  29752  [meat cuts, file powder, smoked sausage, okra,...\n",
      "4  35687  [ground black pepper, salt, sausage casings, l...\n",
      "(9944, 2)\n"
     ]
    }
   ],
   "source": [
    "print(test.head())\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6703\n",
      "4479\n",
      "2647\n",
      "423\n",
      "4056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function gc.collect(generation=2)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting unique ingredients which are present in both test and train datasets. Discarding ingredients which are present\n",
    "# only in test or only in train\n",
    "\n",
    "uniqueIngredients = []\n",
    "for items in train.ingredients:\n",
    "    items = [item.lower().replace(' ', '_') for item in items]\n",
    "    \n",
    "    uniqueIngredients.extend(items)\n",
    "    \n",
    "uniqueIngredientsTrain = set(uniqueIngredients)\n",
    "\n",
    "uniqueIngredients = []\n",
    "for items in test.ingredients:\n",
    "    items = [item.lower().replace(' ', '_') for item in items]\n",
    "    \n",
    "    uniqueIngredients.extend(items)\n",
    "    \n",
    "uniqueIngredientsTest = set(uniqueIngredients)\n",
    "\n",
    "print(len(uniqueIngredientsTrain)) \n",
    "print(len(uniqueIngredientsTest)) \n",
    "print(len(uniqueIngredientsTrain - uniqueIngredientsTest)) \n",
    "print(len(uniqueIngredientsTest - uniqueIngredientsTrain )) \n",
    "print(len(set(uniqueIngredientsTest) & set(uniqueIngredientsTrain)) )\n",
    "\n",
    "uniqueIngredients = list(set(uniqueIngredientsTest) & set(uniqueIngredientsTrain))\n",
    "\n",
    "del uniqueIngredientsTest, uniqueIngredientsTrain\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "italian         7838\n",
       "mexican         6438\n",
       "southern_us     4320\n",
       "indian          3003\n",
       "chinese         2673\n",
       "french          2646\n",
       "cajun_creole    1546\n",
       "thai            1539\n",
       "japanese        1423\n",
       "greek           1175\n",
       "spanish          989\n",
       "korean           830\n",
       "vietnamese       825\n",
       "moroccan         821\n",
       "british          804\n",
       "filipino         755\n",
       "irish            667\n",
       "jamaican         526\n",
       "russian          489\n",
       "brazilian        467\n",
       "Name: cuisine, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.cuisine.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 4059)\n",
      "(9944, 4058)\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Creating one hot encoding on ingredient name\n",
    "# Creating a column for each ingredient, updating the column with 0 and making its type as int8\n",
    "\n",
    "for i in range(len(uniqueIngredients)):\n",
    "    train[uniqueIngredients[i]] = 0\n",
    "    test[uniqueIngredients[i]] = 0\n",
    "    train[uniqueIngredients[i]] = train[uniqueIngredients[i]].astype('int8')\n",
    "    test[uniqueIngredients[i]] = test[uniqueIngredients[i]].astype('int8')\n",
    "\n",
    "#print(\"after for loop\")\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 4059)\n",
      "(9944, 4058)\n",
      "Wall time: 20.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function gc.collect(generation=2)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# looping through train and test data and populating the columns for each ingredient.\n",
    "# if the ingredient is in ingredients column, then the corresponding column get a value 1 (similar to onehot encoding)\n",
    "train.head(2)\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    rowIngred = train['ingredients'][i]\n",
    "    rowIngred = [item.lower().replace(' ', '_') for item in rowIngred]\n",
    "\n",
    "    size = len(rowIngred)\n",
    "    inUnique =[]\n",
    "    for k in range(size):\n",
    "        if rowIngred[k] in uniqueIngredients:\n",
    "            train.at[i, rowIngred[k]] = 1\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    rowIngred = test['ingredients'][i]\n",
    "    rowIngred = [item.lower().replace(' ', '_') for item in rowIngred]\n",
    "    size = len(rowIngred)\n",
    "    for k in range(size):\n",
    "        if rowIngred[k] in uniqueIngredients:\n",
    "            test.at[i, rowIngred[k]] = 1 \n",
    "\n",
    "#print(\"after for loop\")\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "del rowIngred, size\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dropped2933\n",
      "(39774, 1126)\n",
      "(9944, 1125)\n",
      "Wall time: 922 ms\n",
      "Parser   : 110 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# The ingredients that are appearing for less than 40 items are dropped. This significantly reduces the number of columns,\n",
    "# without much sacrifice in accuracy. However, the speed of model training and prediction increases greatly\n",
    "\n",
    "dropped =0\n",
    "dropList =[]\n",
    "for i in uniqueIngredients:\n",
    "    if train[i].sum() <= 40 :\n",
    "        dropped+=1\n",
    "        dropList.append(i)\n",
    "\n",
    "train = train.drop(dropList, axis=1)\n",
    "test = test.drop(dropList, axis=1)\n",
    "\n",
    "print(\"total dropped\" + str(dropped))\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "cuisine               object\n",
       "ingredients           object\n",
       "golden_brown_sugar      int8\n",
       "quinoa                  int8\n",
       "                       ...  \n",
       "refried_beans           int8\n",
       "chili                   int8\n",
       "peas                    int8\n",
       "chorizo_sausage         int8\n",
       "fontina_cheese          int8\n",
       "Length: 1126, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 1123)\n",
      "(9944, 1123)\n"
     ]
    }
   ],
   "source": [
    "Y = train['cuisine']\n",
    "X = train.drop(['id', 'ingredients','cuisine'], axis=1)\n",
    "\n",
    "XUnseen = test.drop(['id', 'ingredients'], axis=1)\n",
    "\n",
    "print(X.shape)\n",
    "print(XUnseen.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=2111,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state = 0, max_iter = 2111) \n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7519483784463253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "print (\"Accuracy : \", accuracy_score(y_test, y_pred)) \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "#print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction saved to file\n"
     ]
    }
   ],
   "source": [
    "pred_Test = classifier.predict(XUnseen)\n",
    "\n",
    "dict = {\"id\": test.id, \"cuisine\" : pred_Test}\n",
    "predictDF = pd.DataFrame(dict)\n",
    "\n",
    "predictDF.to_csv(\"Logistic.csv\")\n",
    "print(\"prediction saved to file\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
